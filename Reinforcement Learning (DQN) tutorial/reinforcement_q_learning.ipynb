{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reinforcement_q_learning.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"TJUElOwxCQlX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install Pytorch.\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s-4JiOCCCPpc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HxviWpRKCPpg","colab_type":"text"},"cell_type":"markdown","source":["\n","Reinforcement Learning (DQN) tutorial\n","=====================================\n","**Author**: `Adam Paszke <https://github.com/apaszke>`_\n","\n","\n","This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n","on the CartPole-v0 task from the `OpenAI Gym <https://gym.openai.com/>`__.\n","\n","**Task**\n","\n","The agent has to decide between two actions - moving the cart left or\n","right - so that the pole attached to it stays upright. You can find an\n","official leaderboard with various algorithms and visualizations at the\n","`Gym website <https://gym.openai.com/envs/CartPole-v0>`__.\n","\n",".. figure:: /_static/img/cartpole.gif\n","   :alt: cartpole\n","\n","   cartpole\n","\n","As the agent observes the current state of the environment and chooses\n","an action, the environment *transitions* to a new state, and also\n","returns a reward that indicates the consequences of the action. In this\n","task, the environment terminates if the pole falls over too far.\n","\n","The CartPole task is designed so that the inputs to the agent are 4 real\n","values representing the environment state (position, velocity, etc.).\n","However, neural networks can solve the task purely by looking at the\n","scene, so we'll use a patch of the screen centered on the cart as an\n","input. Because of this, our results aren't directly comparable to the\n","ones from the official leaderboard - our task is much harder.\n","Unfortunately this does slow down the training, because we have to\n","render all the frames.\n","\n","Strictly speaking, we will present the state as the difference between\n","the current screen patch and the previous one. This will allow the agent\n","to take the velocity of the pole into account from one image.\n","\n","**Packages**\n","\n","\n","First, let's import needed packages. Firstly, we need\n","`gym <https://gym.openai.com/docs>`__ for the environment\n","(Install using `pip install gym`).\n","We'll also use the following from PyTorch:\n","\n","-  neural networks (``torch.nn``)\n","-  optimization (``torch.optim``)\n","-  automatic differentiation (``torch.autograd``)\n","-  utilities for vision tasks (``torchvision`` - `a separate\n","   package <https://github.com/pytorch/vision>`__).\n","\n","\n"]},{"metadata":{"id":"9KOIJ3zBD6v3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":357},"outputId":"caf25fc2-7dfb-4460-a6bc-56631a48ec3f","executionInfo":{"status":"ok","timestamp":1523271590784,"user_tz":-480,"elapsed":7097,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["!pip install gym"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting gym\n","  Downloading gym-0.10.5.tar.gz (1.5MB)\n","\u001b[K    100% |████████████████████████████████| 1.5MB 785kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym)\n","Collecting pyglet>=1.2.0 (from gym)\n","  Downloading pyglet-1.3.1-py2.py3-none-any.whl (1.0MB)\n","\u001b[K    100% |████████████████████████████████| 1.0MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Building wheels for collected packages: gym\n","  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f8/88/f2/22e53080a462567706fad31295462941b3b06b16b51c3ab3e1\n","Successfully built gym\n","Installing collected packages: pyglet, gym\n","Successfully installed gym-0.10.5 pyglet-1.3.1\n"],"name":"stdout"}]},{"metadata":{"id":"fOuHqIHDCPph","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"6d210bbc-37e9-4a8c-91f1-ae2ff268e314","executionInfo":{"status":"ok","timestamp":1523274310534,"user_tz":-480,"elapsed":7856,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["import math\n","import random\n","from collections import namedtuple\n","from itertools import count\n","\n","import gym\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision.transforms as T\n","\n","\n","env = gym.make('CartPole-v0').unwrapped\n","\n","# Set up matplotlib\n","is_ipython = 'inline' in matplotlib.get_backend()\n","if is_ipython:\n","    from IPython import display\n","\n","plt.ion()\n","\n","# If gpu is to be used.\n","use_cuda = torch.cuda.is_available()\n","FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n","ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n","Tensor = FloatTensor"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"],"name":"stdout"}]},{"metadata":{"id":"8NZv8ysrCPpj","colab_type":"text"},"cell_type":"markdown","source":["Replay Memory\n","-------------\n","\n","We'll be using experience replay memory for training our DQN. It stores\n","the transitions that the agent observes, allowing us to reuse this data\n","later. By sampling from it randomly, the transitions that build up a\n","batch are decorrelated. It has been shown that this greatly stabilizes\n","and improves the DQN training procedure.\n","\n","For this, we're going to need two classses:\n","\n","-  ``Transition`` - a named tuple representing a single transition in\n","   our environment\n","-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n","   transitions observed recently. It also implements a ``.sample()``\n","   method for selecting a random batch of transitions for training.\n","\n","\n"]},{"metadata":{"id":"VqMIK8WXPCU3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Transition = namedtuple(\"Transition\", \n","                        (\"state\", \"action\", \"next_state\", \"reward\"))\n","\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","        \n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","        \n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","    \n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sRK-e2YXCPpm","colab_type":"text"},"cell_type":"markdown","source":["Now, let's define our model. But first, let quickly recap what a DQN is.\n","\n","DQN algorithm\n","-------------\n","\n","Our environment is deterministic, so all equations presented here are\n","also formulated deterministically for the sake of simplicity. In the\n","reinforcement learning literature, they would also contain expectations\n","over stochastic transitions in the environment.\n","\n","Our aim will be to train a policy that tries to maximize the discounted,\n","cumulative reward\n","$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n","$R_{t_0}$ is also known as the *return*. The discount,\n","$\\gamma$, should be a constant between $0$ and $1$\n","that ensures the sum converges. It makes rewards from the uncertain far\n","future less important for our agent than the ones in the near future\n","that it can be fairly confident about.\n","\n","The main idea behind Q-learning is that if we had a function\n","$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n","us what our return would be, if we were to take an action in a given\n","state, then we could easily construct a policy that maximizes our\n","rewards:\n","\n","\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n","\n","However, we don't know everything about the world, so we don't have\n","access to $Q^*$. But, since neural networks are universal function\n","approximators, we can simply create one and train it to resemble\n","$Q^*$.\n","\n","For our training update rule, we'll use a fact that every $Q$\n","function for some policy obeys the Bellman equation:\n","\n","\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n","\n","The difference between the two sides of the equality is known as the\n","temporal difference error, $\\delta$:\n","\n","\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}\n","\n","To minimise this error, we will use the `Huber\n","loss <https://en.wikipedia.org/wiki/Huber_loss>`__. The Huber loss acts\n","like the mean squared error when the error is small, but like the mean\n","absolute error when the error is large - this makes it more robust to\n","outliers when the estimates of $Q$ are very noisy. We calculate\n","this over a batch of transitions, $B$, sampled from the replay\n","memory:\n","\n","\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n","\n","\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n","     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n","     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n","   \\end{cases}\\end{align}\n","\n","Q-network\n","^^^^^^^^^\n","\n","Our model will be a convolutional neural network that takes in the\n","difference between the current and previous screen patches. It has two\n","outputs, representing $Q(s, \\mathrm{left})$ and\n","$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n","network). In effect, the network is trying to predict the *quality* of\n","taking each action given the current input.\n","\n","\n"]},{"metadata":{"id":"GuzmSWSgCPpn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class DQN(nn.Module):\n","\n","    def __init__(self):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","        self.head = nn.Linear(448, 2)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HkhYCrheCPpp","colab_type":"text"},"cell_type":"markdown","source":["Input extraction\n","^^^^^^^^^^^^^^^^\n","\n","The code below are utilities for extracting and processing rendered\n","images from the environment. It uses the ``torchvision`` package, which\n","makes it easy to compose image transforms. Once you run the cell it will\n","display an example patch that it extracted.\n","\n","\n"]},{"metadata":{"id":"epbQY4epUWTW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2876},"outputId":"0c8536bb-a61e-4572-a2a4-dbef77650edb","executionInfo":{"status":"ok","timestamp":1523275928886,"user_tz":-480,"elapsed":18266,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["!apt-get install python-opengl"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  freeglut3 libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2\n","  libdrm-radeon1 libdrm2 libelf1 libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa\n","  libglu1-mesa libllvm5.0 libpciaccess0 libsensors4 libtxc-dxtn-s2tc\n","  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n","  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxxf86vm1\n","Suggested packages:\n","  pciutils lm-sensors python-tk python-numpy libgle3\n","The following NEW packages will be installed:\n","  freeglut3 libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2\n","  libdrm-radeon1 libdrm2 libelf1 libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa\n","  libglu1-mesa libllvm5.0 libpciaccess0 libsensors4 libtxc-dxtn-s2tc\n","  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n","  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxxf86vm1\n","  python-opengl\n","0 upgraded, 28 newly installed, 0 to remove and 0 not upgraded.\n","Need to get 20.7 MB of archives.\n","After this operation, 194 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu artful/main amd64 libxshmfence1 amd64 1.2-1 [5,042 B]\n","Get:2 http://archive.ubuntu.com/ubuntu artful/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu artful/main amd64 libelf1 amd64 0.170-0.1 [44.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-common all 2.4.83-1 [4,938 B]\n","Get:5 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm2 amd64 2.4.83-1 [30.6 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libglapi-mesa amd64 17.2.8-0ubuntu0~17.10.1 [22.2 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu artful/main amd64 libx11-xcb1 amd64 2:1.6.4-3 [9,626 B]\n","Get:8 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-dri2-0 amd64 1.12-1ubuntu1 [6,838 B]\n","Get:9 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-dri3-0 amd64 1.12-1ubuntu1 [5,156 B]\n","Get:10 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-glx0 amd64 1.12-1ubuntu1 [22.3 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-present0 amd64 1.12-1ubuntu1 [5,436 B]\n","Get:12 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-sync1 amd64 1.12-1ubuntu1 [8,746 B]\n","Get:13 http://archive.ubuntu.com/ubuntu artful/main amd64 libxdamage1 amd64 1:1.1.4-3 [6,934 B]\n","Get:14 http://archive.ubuntu.com/ubuntu artful/main amd64 libxfixes3 amd64 1:5.0.3-1 [10.8 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-amdgpu1 amd64 2.4.83-1 [18.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu artful/main amd64 libpciaccess0 amd64 0.13.4-1ubuntu1 [17.9 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-intel1 amd64 2.4.83-1 [59.7 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-nouveau2 amd64 2.4.83-1 [16.4 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-radeon1 amd64 2.4.83-1 [21.6 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu artful/main amd64 libllvm5.0 amd64 1:5.0-3 [13.7 MB]\n","Get:21 http://archive.ubuntu.com/ubuntu artful/main amd64 libsensors4 amd64 1:3.4.0-4 [28.8 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libgl1-mesa-dri amd64 17.2.8-0ubuntu0~17.10.1 [5,707 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libgl1-mesa-glx amd64 17.2.8-0ubuntu0~17.10.1 [130 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu artful/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu artful/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu artful/main amd64 libglu1-mesa amd64 9.0.0-2.1build1 [168 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu artful/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu artful/main amd64 libtxc-dxtn-s2tc amd64 1.0+git20151227-2 [48.4 kB]\n","Fetched 20.7 MB in 2s (7,780 kB/s)\n","Selecting previously unselected package libxshmfence1:amd64.\n","(Reading database ... 16712 files and directories currently installed.)\n","Preparing to unpack .../00-libxshmfence1_1.2-1_amd64.deb ...\n","Unpacking libxshmfence1:amd64 (1.2-1) ...\n","Selecting previously unselected package libxxf86vm1:amd64.\n","Preparing to unpack .../01-libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n","Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n","Selecting previously unselected package libelf1:amd64.\n","Preparing to unpack .../02-libelf1_0.170-0.1_amd64.deb ...\n","Unpacking libelf1:amd64 (0.170-0.1) ...\n","Selecting previously unselected package libdrm-common.\n","Preparing to unpack .../03-libdrm-common_2.4.83-1_all.deb ...\n","Unpacking libdrm-common (2.4.83-1) ...\n","Selecting previously unselected package libdrm2:amd64.\n","Preparing to unpack .../04-libdrm2_2.4.83-1_amd64.deb ...\n","Unpacking libdrm2:amd64 (2.4.83-1) ...\n","Selecting previously unselected package libglapi-mesa:amd64.\n","Preparing to unpack .../05-libglapi-mesa_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n","Unpacking libglapi-mesa:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n","Selecting previously unselected package libx11-xcb1:amd64.\n","Preparing to unpack .../06-libx11-xcb1_2%3a1.6.4-3_amd64.deb ...\n","Unpacking libx11-xcb1:amd64 (2:1.6.4-3) ...\n"],"name":"stdout"},{"output_type":"stream","text":["Selecting previously unselected package libxcb-dri2-0:amd64.\r\n","Preparing to unpack .../07-libxcb-dri2-0_1.12-1ubuntu1_amd64.deb ...\r\n","Unpacking libxcb-dri2-0:amd64 (1.12-1ubuntu1) ...\n","Selecting previously unselected package libxcb-dri3-0:amd64.\n","Preparing to unpack .../08-libxcb-dri3-0_1.12-1ubuntu1_amd64.deb ...\n","Unpacking libxcb-dri3-0:amd64 (1.12-1ubuntu1) ...\n","Selecting previously unselected package libxcb-glx0:amd64.\n","Preparing to unpack .../09-libxcb-glx0_1.12-1ubuntu1_amd64.deb ...\n","Unpacking libxcb-glx0:amd64 (1.12-1ubuntu1) ...\n","Selecting previously unselected package libxcb-present0:amd64.\n","Preparing to unpack .../10-libxcb-present0_1.12-1ubuntu1_amd64.deb ...\n","Unpacking libxcb-present0:amd64 (1.12-1ubuntu1) ...\n","Selecting previously unselected package libxcb-sync1:amd64.\n","Preparing to unpack .../11-libxcb-sync1_1.12-1ubuntu1_amd64.deb ...\n","Unpacking libxcb-sync1:amd64 (1.12-1ubuntu1) ...\n","Selecting previously unselected package libxdamage1:amd64.\n","Preparing to unpack .../12-libxdamage1_1%3a1.1.4-3_amd64.deb ...\n","Unpacking libxdamage1:amd64 (1:1.1.4-3) ...\n","Selecting previously unselected package libxfixes3:amd64.\n","Preparing to unpack .../13-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n","Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n","Selecting previously unselected package libdrm-amdgpu1:amd64.\n","Preparing to unpack .../14-libdrm-amdgpu1_2.4.83-1_amd64.deb ...\n","Unpacking libdrm-amdgpu1:amd64 (2.4.83-1) ...\n","Selecting previously unselected package libpciaccess0:amd64.\n","Preparing to unpack .../15-libpciaccess0_0.13.4-1ubuntu1_amd64.deb ...\n","Unpacking libpciaccess0:amd64 (0.13.4-1ubuntu1) ...\n","Selecting previously unselected package libdrm-intel1:amd64.\n","Preparing to unpack .../16-libdrm-intel1_2.4.83-1_amd64.deb ...\n","Unpacking libdrm-intel1:amd64 (2.4.83-1) ...\n","Selecting previously unselected package libdrm-nouveau2:amd64.\n","Preparing to unpack .../17-libdrm-nouveau2_2.4.83-1_amd64.deb ...\n","Unpacking libdrm-nouveau2:amd64 (2.4.83-1) ...\n","Selecting previously unselected package libdrm-radeon1:amd64.\n","Preparing to unpack .../18-libdrm-radeon1_2.4.83-1_amd64.deb ...\n","Unpacking libdrm-radeon1:amd64 (2.4.83-1) ...\n","Selecting previously unselected package libllvm5.0:amd64.\n","Preparing to unpack .../19-libllvm5.0_1%3a5.0-3_amd64.deb ...\n","Unpacking libllvm5.0:amd64 (1:5.0-3) ...\n","Selecting previously unselected package libsensors4:amd64.\n","Preparing to unpack .../20-libsensors4_1%3a3.4.0-4_amd64.deb ...\n","Unpacking libsensors4:amd64 (1:3.4.0-4) ...\n","Selecting previously unselected package libgl1-mesa-dri:amd64.\n","Preparing to unpack .../21-libgl1-mesa-dri_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n","Unpacking libgl1-mesa-dri:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n","Selecting previously unselected package libgl1-mesa-glx:amd64.\n","Preparing to unpack .../22-libgl1-mesa-glx_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n","Unpacking libgl1-mesa-glx:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n","Selecting previously unselected package libxi6:amd64.\n","Preparing to unpack .../23-libxi6_2%3a1.7.9-1_amd64.deb ...\n","Unpacking libxi6:amd64 (2:1.7.9-1) ...\n","Selecting previously unselected package freeglut3:amd64.\n","Preparing to unpack .../24-freeglut3_2.8.1-3_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-3) ...\n","Selecting previously unselected package libglu1-mesa:amd64.\n","Preparing to unpack .../25-libglu1-mesa_9.0.0-2.1build1_amd64.deb ...\n","Unpacking libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n","Selecting previously unselected package python-opengl.\n","Preparing to unpack .../26-python-opengl_3.1.0+dfsg-1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-1) ...\n","Selecting previously unselected package libtxc-dxtn-s2tc:amd64.\n","Preparing to unpack .../27-libtxc-dxtn-s2tc_1.0+git20151227-2_amd64.deb ...\n","Unpacking libtxc-dxtn-s2tc:amd64 (1.0+git20151227-2) ...\n","Setting up libxi6:amd64 (2:1.7.9-1) ...\n","Setting up libxcb-present0:amd64 (1.12-1ubuntu1) ...\n","Setting up libxcb-dri2-0:amd64 (1.12-1ubuntu1) ...\n","Setting up libxcb-dri3-0:amd64 (1.12-1ubuntu1) ...\n","Setting up libxcb-glx0:amd64 (1.12-1ubuntu1) ...\n","Setting up libxdamage1:amd64 (1:1.1.4-3) ...\n","Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n","Setting up libelf1:amd64 (0.170-0.1) ...\n","Setting up libxshmfence1:amd64 (1.2-1) ...\n","Setting up libllvm5.0:amd64 (1:5.0-3) ...\n","Setting up libtxc-dxtn-s2tc:amd64 (1.0+git20151227-2) ...\n","update-alternatives: using /usr/lib/x86_64-linux-gnu/s2tc/libtxc_dxtn.so to provide /usr/lib/x86_64-linux-gnu/libtxc_dxtn.so (libtxc-dxtn-x86_64-linux-gnu) in auto mode\n","Setting up libglapi-mesa:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n","Setting up libdrm-common (2.4.83-1) ...\n","Setting up libxcb-sync1:amd64 (1.12-1ubuntu1) ...\n","Setting up libx11-xcb1:amd64 (2:1.6.4-3) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up libpciaccess0:amd64 (0.13.4-1ubuntu1) ...\n","Setting up libsensors4:amd64 (1:3.4.0-4) ...\n","Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n","Setting up libdrm2:amd64 (2.4.83-1) ...\n","Setting up libdrm-intel1:amd64 (2.4.83-1) ...\n","Setting up libdrm-radeon1:amd64 (2.4.83-1) ...\n","Setting up libdrm-nouveau2:amd64 (2.4.83-1) ...\n"],"name":"stdout"},{"output_type":"stream","text":["Setting up libdrm-amdgpu1:amd64 (2.4.83-1) ...\r\n","Setting up libgl1-mesa-dri:amd64 (17.2.8-0ubuntu0~17.10.1) ...\r\n","Setting up libgl1-mesa-glx:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n","update-alternatives: using /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n","Setting up libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n","Setting up freeglut3:amd64 (2.8.1-3) ...\n","Setting up python-opengl (3.1.0+dfsg-1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"],"name":"stdout"}]},{"metadata":{"id":"qRl7kafzUWqV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":745},"outputId":"3ff58d12-c1b5-460e-807c-5fa7eaf490b8","executionInfo":{"status":"error","timestamp":1523281146762,"user_tz":-480,"elapsed":1314,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(40, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","# This is based on the code from gym.\n","screen_width = 600\n","\n","\n","def get_cart_location():\n","    world_width = env.x_threshold * 2\n","    scale = screen_width / world_width\n","    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n","\n","\n","def get_screen():\n","    # transpose into torch order (CHW)\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    # Strip off the top and bottom of the screen\n","    screen = screen[:, 160:320]\n","    view_width = 320\n","    cart_location = get_cart_location()\n","    if cart_location < view_width // 2:\n","        slice_range = slice(view_width)\n","    elif cart_location > (screen_width - view_width // 2):\n","        slice_range = slice(-view_width, None)\n","    else:\n","        slice_range = slice(cart_location - view_width // 2,\n","                            cart_location + view_width // 2)\n","    # Strip off the edges, so that we have a square image centered on a cart\n","    screen = screen[:, :, slice_range]\n","    # Convert to float, rescare, convert to torch tensor\n","    # (this doesn't require a copy)\n","    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n","    screen = torch.from_numpy(screen)\n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0).type(Tensor)\n","\n","\n","env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-44b1a77d28d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n\u001b[0m\u001b[1;32m     42\u001b[0m            interpolation='none')\n\u001b[1;32m     43\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example extracted screen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-44b1a77d28d8>\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# transpose into torch order (CHW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Strip off the top and bottom of the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcarbon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarbonConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;31m# XXX remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<matplotlib.figure.Figure at 0x7f144a9156a0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"NrS8JSx5CPpt","colab_type":"text"},"cell_type":"markdown","source":["Training\n","--------\n","\n","Hyperparameters and utilities\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","This cell instantiates our model and its optimizer, and defines some\n","utilities:\n","\n","-  ``Variable`` - this is a simple wrapper around\n","   ``torch.autograd.Variable`` that will automatically send the data to\n","   the GPU every time we construct a Variable.\n","-  ``select_action`` - will select an action accordingly to an epsilon\n","   greedy policy. Simply put, we'll sometimes use our model for choosing\n","   the action, and sometimes we'll just sample one uniformly. The\n","   probability of choosing a random action will start at ``EPS_START``\n","   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n","   controls the rate of the decay.\n","-  ``plot_durations`` - a helper for plotting the durations of episodes,\n","   along with an average over the last 100 episodes (the measure used in\n","   the official evaluations). The plot will be underneath the cell\n","   containing the main training loop, and will update after every\n","   episode.\n","\n","\n"]},{"metadata":{"id":"Xgl9ru5ACPpt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["BATCH_SIZE = 128\n","GAMMA = 0.999\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 200\n","TARGET_UPDATE = 10\n","\n","policy_net = DQN()\n","target_net = DQN()\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","if use_cuda:\n","    policy_net.cuda()\n","    target_net.cuda()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        return policy_net(\n","            Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n","    else:\n","        return LongTensor([[random.randrange(2)]])\n","\n","\n","episode_durations = []\n","\n","\n","def plot_durations():\n","    plt.figure(2)\n","    plt.clf()\n","    durations_t = torch.FloatTensor(episode_durations)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    if is_ipython:\n","        display.clear_output(wait=True)\n","        display.display(plt.gcf())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rg2Sd-MbCPpw","colab_type":"text"},"cell_type":"markdown","source":["Training loop\n","^^^^^^^^^^^^^\n","\n","Finally, the code for training our model.\n","\n","Here, you can find an ``optimize_model`` function that performs a\n","single step of the optimization. It first samples a batch, concatenates\n","all the tensors into a single one, computes $Q(s_t, a_t)$ and\n","$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n","loss. By defition we set $V(s) = 0$ if $s$ is a terminal\n","state. We also use a target network to compute $V(s_{t+1})$ for\n","added stability. The target network has its weights kept frozen most of\n","the time, but is updated with the policy network's weights every so often.\n","This is usually a set number of steps but we shall use episodes for\n","simplicity.\n","\n","\n"]},{"metadata":{"id":"EJL3s-0GCPpw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation).\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)))\n","    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n","                                                if s is not None]),\n","                                     volatile=True)\n","    state_batch = Variable(torch.cat(batch.state))\n","    action_batch = Variable(torch.cat(batch.action))\n","    reward_batch = Variable(torch.cat(batch.reward))\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(Tensor))\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","    # Undo volatility (which was used to prevent unnecessary gradients)\n","    expected_state_action_values = Variable(expected_state_action_values.data)\n","\n","    # Compute Huber loss\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G683A7YBCPpz","colab_type":"text"},"cell_type":"markdown","source":["Below, you can find the main training loop. At the beginning we reset\n","the environment and initialize the ``state`` variable. Then, we sample\n","an action, execute it, observe the next screen and the reward (always\n","1), and optimize our model once. When the episode ends (our model\n","fails), we restart the loop.\n","\n","Below, `num_episodes` is set small. You should download\n","the notebook and run lot more epsiodes.\n","\n","\n"]},{"metadata":{"id":"1MH6RRJbCPp0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":728},"outputId":"d2dbea8e-b016-4b17-859f-23c3a34c2477","executionInfo":{"status":"error","timestamp":1523281271331,"user_tz":-480,"elapsed":771,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["num_episodes = 50\n","for i_episode in range(num_episodes):\n","    # Initialize the environment and state\n","    env.reset()\n","    last_screen = get_screen()\n","    current_screen = get_screen()\n","    state = current_screen - last_screen\n","    for t in count():\n","        # Select and perform an action\n","        action = select_action(state)\n","        _, reward, done, _ = env.step(action[0, 0])\n","        reward = Tensor([reward])\n","\n","        # Observe new state\n","        last_screen = current_screen\n","        current_screen = get_screen()\n","        if not done:\n","            next_state = current_screen - last_screen\n","        else:\n","            next_state = None\n","\n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","\n","        # Move to the next state\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the target network)\n","        optimize_model()\n","        if done:\n","            episode_durations.append(t + 1)\n","            plot_durations()\n","            break\n","    # Update the target network\n","    if i_episode % TARGET_UPDATE == 0:\n","        target_net.load_state_dict(policy_net.state_dict())\n","\n","print('Complete')\n","env.render(close=True)\n","env.close()\n","plt.ioff()\n","plt.show()"],"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-29da8a7d145b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Initialize the environment and state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlast_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcurrent_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_screen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-44b1a77d28d8>\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# transpose into torch order (CHW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Strip off the top and bottom of the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcarbon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarbonConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;31m# XXX remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"]}]},{"metadata":{"id":"4EtV9l-Fo5Xr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}